# Cutomer-Feeback-Analyzer
this project is a real-world NLP challenge

  # Starting

## Stage1 : 
  Data tested has been generated using AI for testing purpose.

## ğŸ§¹ Stage 2: Preprocessing â€” Cleaning the Customer Feedbacks

### ğŸ“˜ Purpose

In this stage I clean all the feedback text before sending it to NLP model.
Main goal is to make text clear, simple, and ready for analysis.
Because raw feedback has too much noise â€” emojis, hashtags, links, Urdu+English mix, and random characters â€” all this confuse model.

---

### âš™ï¸ What this stage do

I make a pipeline that perform these main steps:

1. **Text Normalization**

   * Change all words to lowercase.
   * Remove extra spaces, punctuation, and URLs.
   * Example: â€œWOW!!! Service was Great!!!â€ â†’ â€œwow service was greatâ€

2. **Stopword Removal**

   * I remove common useless words like *is, am, the, hai, main, ka, ke, ki*, etc.
   * These words not help model to understand feeling or topic.
   * Used stopword list from NLTK for English and plan to build one for Urdu later.

3. **Tokenization**

   * Break sentence into words (tokens).
   * Example: â€œservice was greatâ€ â†’ `[â€œserviceâ€, â€œgreatâ€]`

4. **Lemmatization / Stemming**

   * Convert words to their base form.
   * Example: â€œservicesâ€, â€œservingâ€ â†’ â€œserviceâ€.
   * Helps to treat all same-meaning words as one.

---

### ğŸ”§ Libraries Used

* **re** â†’ for regex cleaning (remove URLs, mentions, hashtags).
* **nltk** â†’ for stopwords, tokenization, lemmatization.
* **emoji** â†’ (later) for removing or converting emojis to text like â€œğŸ˜Šâ€ â†’ â€œhappyâ€.
* **contractions** â†’ (later) to expand short forms like â€œdonâ€™tâ€ â†’ â€œdo notâ€.
* **textblob** â†’ (optional) for correction and sentiment check.

---

### ğŸ§± Structure of Data after this Stage

Now my dataset looks like this:

| id | text                     | cleaned               |
| -- | ------------------------ | --------------------- |
| 1  | â€œService was excellent!â€ | â€œservice excellentâ€   |
| 2  | â€œProduct not working ğŸ˜â€ | â€œproduct not workingâ€ |

âœ… `id` = just serial number (will drop later)
âœ… `text` = original feedback
âœ… `cleaned` = ready text for next NLP step

---

### ğŸ§  Challenges I Faced

| Problem                                   | Why it happened                                     | How I solved it                                                   |                                 |        |
| ----------------------------------------- | --------------------------------------------------- | ----------------------------------------------------------------- | ------------------------------- | ------ |
| **Too much noise in text**                | People write URLs, tags, emojis                     | Used regex to remove `http`, `www`, `@username`, `#tag`           |                                 |        |
| **Regex not working**                     | I wrote spaces around `                             | ` symbol                                                          | Learned correct syntax: `r'@\w+ | #\w+'` |
| **Extra spaces after cleaning**           | Multiple spaces remained after removing URLs        | Added `re.sub(r'\s+', ' ', text)`                                 |                                 |        |
| **Confusion between index and id column** | CSV saved both index and `id`                       | Used `df.drop(columns=['id'])` and `index=False`                  |                                 |        |
| **Urdu + English mix text**               | Some feedbacks are bilingual                        | Decided to clean English first, plan Urdu normalization later     |                                 |        |
| **Code looked confusing**                 | Many steps in one function                          | Broke it into small functions: regex cleaning, tokenization, etc. |                                 |        |
| **Understanding what each line does**     | I didnâ€™t know why `.strip()`, `.lower()`, etc. used | Tested step-by-step and understood purpose manually               |                                 |        |

---

### ğŸ§­ Lessons Learned

* Always test small pieces of code to understand logic.
* Regex spaces matter â€” one wrong space can break cleaning.
* Cleaning text is not â€œone formulaâ€; it depends on language and data style.
* Keep both raw and cleaned versions â€” helps debug errors later.

---




